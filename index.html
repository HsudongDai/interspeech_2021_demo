<html>

<head>
    <link rel="shortcut icon" href="mic.svg">
    <style>
        h1 {
            font-family: 'Open Sans', sans-serif;
            font-size: 24px;
            line-height: 250%;
            font-weight: 500;
            text-rendering: optimizeLegibility;
        }

        h2 {
            font-size: 18px;
            font-family: 'Open Sans', sans-serif;
            letter-spacing: 1px;
            font-weight: 300;
            line-height: 150%;
            text-rendering: optimizeLegibility;
        }

        body {
            font: normal 12px/150% Arial, Helvetica, sans-serif;
            background: #fff;
        }

        table {
            width: 95%;
            border-collapse: collapse;
        }

        td {
            border: 1px solid black;
            border-collapse: inherit;
            padding: 2px 2px;
            text-align: center;
            word-wrap: break-word;
            width: 8%;
        }

        th {
            padding: 3px 10px;
            font-family: 'Open Sans', sans-serif;
            font-weight: 100;
            color: #000000;
            font-size: 15px;
            border-left: 1px solid black;
            height: 30px;
        }

        table tr {
            color: #000000;
            border: 1px solid black;
            font-size: 12px;
            font-weight: normal;
            height: 40px;
        }

        audio {
            width: 150px;
            padding: 1px;
        }

        div {
            font-family: 'Century', sans-serif;
            font-weight: 100;
            font-size: 14px;
            line-height: 24px;
        }

        .sample {
            font-size: 15px;
            font-style: italic;
            border: 1px solid #ddd;
            padding: 3px;
            margin-bottom: 2px;
        }
    </style>

    <meta charset="UTF-8">
    <title>Audio samples for Interspeech 2021"</title>
</head>

<body>
<article>
    <header>
        <h2 align="center">Audio Samples from</h2><br>
        <h1 align="center">"INFORMATION SIEVE: CONTENT LEAKAGE REDUCTION IN END-TO-END PROSODY TRANSFER FOR EXPRESSIVE
            SPEECH SYNTHESIS"</h1>
    </header>
</article>
<!-- <br> -->
<!-- <div style="font-size: 20px;"><b>Paper:</b> <a href="https://arxiv.org/">arXiv</a> </div> -->
<br>
<div style="font-size: 20px;" align="center"><b>Authors:</b>Xudong Dai, Cheng Gong, Longbiao Wang, Kaili Zhang</div>
<br>
<div style="font-size: 18px; width: auto">
    <span style="font-weight: bold">Abstract: </span>
    Expressive neural text-to-speech (TTS) systems incorporate a style encoder to learn a latent embedding as the style
    information. However, this embedding process may encode redundant textual information. This phenomenon is called
    content leakage. Researchers have attempted to resolve this problem by adding an ASR or other auxiliary supervision
    loss functions. In this study, we propose an unsupervised method called the ‘‘information sieve’’ to reduce the
    effect of content leakage in prosody transfer. The rationale of this approach is that the style encoder can be
    forced to focus on style information rather than on textual information contained in the reference speech by a
    well-designed downsample--upsample filter, i.e., the extracted style embeddings can be downsampled at a certain
    interval and then upsampled by duplication. Furthermore, we used instance normalization in convolution layers to
    help the system learn a better latent style space. Objective metrics such as the significantly lower word error rate
    (WER) demonstrate the effectiveness of this model in mitigating content leakage . Listening tests indicate that the
    model retains its prosody transferability compared with the baseline models such as the original GST-Tacotron and
    ASR-guided Tacotron.
</div>

<br>

<div>
    <h2 style="font-weight: bold">Definition (same as defined in our submitted paper)</h2>
    <strong>Ground Truth</strong>: Records directly selected from testset in Blizzard Challenge 2013<br>
    <strong>Original GST-Tacotron</strong>: Original Tacotron model combined with Global Style Tokens.<br>
    <strong>Sieve GST</strong>: GST Tacotron style encoder combined with an Information Sieve layer.<br>
    <strong>I-G</strong>: Replace batch normalization used in convolutional layers of style encoder with instance
    normalization.<br>
    <strong>S-I-G model</strong>: Our proposed model with Information Sieve and Instance Normalization in our style
    encoder.<br>
</div>

<p class="sample">
    1.This is not the first time, but it shall be the last.
</p>
<blockquote>
    <table style="table-layout: auto">
        <tr>
            <td>Ground Truth Record & Target Reference Audio</td>
            <td>Original GST (using target reference)</td>
            <td>Sieve GST (using target reference)</td>
            <td>I-G (using target reference)</td>
            <td>S-I-G (using target reference)</td>
            <!-- A halving line for counting -->
            <td>Ground Truth random reference audio</td>
            <td>Original GST (using random reference)</td>
            <td>Sieve GST (using random reference)</td>
            <td>I-G (using random reference)</td>
            <td>S-I-G (using random reference)</td>
        </tr>
        <tr>
            <td rowspan=2>
                <audio src="sentence1/CA-BB-01-39.wav" controls preload="metadata"></audio>
            </td>
            <td rowspan=2>
                <audio src="sentence1/origin-eval-188000_CA-BB-01-39_ref-mel.wav" controls preload="metadata"></audio>
            </td>
            <td rowspan=2>
                <audio src="sentence1/batch-eval-188000_CA-BB-01-39_ref-mel.wav" controls preload="metadata"></audio>
            </td>
            <td rowspan=2>
                <audio src="sentence1/instance-eval-188000_CA-BB-01-39_ref-self.wav" controls
                       preload="metadata"></audio>
            </td>
            <td rowspan=2>
                <audio src="sentence1/eval-188000_CA-BB-01-39_CA-MP1-13-049.wav" controls preload="metadata"></audio>
            </td>
            <td>
                <audio src="sentence1/CA-MP1-13-049.wav" controls preload="metadata"></audio>
            </td>
            <td>
                <audio src="sentence1/origin-eval-188000_CA-BB-01-39_ref-CA-MP1-13-049.wav" controls
                       preload="metadata"></audio>
            </td>
            <td>
                <audio src="sentence1/batch-eval-188000_CA-BB-01-39_ref-CA-MP1-13-049.wav" controls
                       preload="metadata"></audio>
            </td>
            <td>
                <audio src="sentence1/instance-eval-188000_CA-BB-01-39_ref-CA-MP1-13-049.wav" controls
                       preload="metadata"></audio>
            </td>
            <td>
                <audio src="sentence1/eval-188000_CA-BB-01-39_CA-MP1-13-049.wav" controls preload="metadata"></audio>
            </td>
        </tr>
        <tr>
            <td>
                <audio src="sentence1/CA-MP3-17-131.wav" controls preload="metadata"></audio>
            </td>
            <td>
                <audio src="sentence1/origin-eval-188000_CA-BB-01-39_ref-CA-MP3-17-131.wav" controls
                       preload="metadata"></audio>
            </td>
            <td>
                <audio src="sentence1/batch-eval-188000_CA-BB-01-39_ref-CA-MP3-17-131.wav" controls
                       preload="metadata"></audio>
            </td>
            <td>
                <audio src="sentence1/instance-eval-188000_CA-BB-01-39_ref-CA-MP3-17-131.wav" controls
                       preload="metadata"></audio>
            </td>
            <td>
                <audio src="sentence1/eval-188000_CA-BB-01-39_CA-MP3-17-131.wav" controls preload="metadata"></audio>
            </td>
        </tr>
    </table>
</blockquote>

<br>
<br>
<br>
</body>

</html>
